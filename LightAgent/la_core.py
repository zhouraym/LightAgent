#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ä½œè€…: [weego/WXAI-Team]
ç‰ˆæœ¬: 0.4.8
æœ€åæ›´æ–°: 2025-12-14
"""

import asyncio
import importlib
import importlib.util
import inspect
import json
import logging
import os
import random
import re
import traceback
from contextlib import AsyncExitStack
from copy import deepcopy
from datetime import datetime
from functools import partial
from typing import List, Dict, Any, Callable, Union, Optional, Generator, AsyncGenerator, Protocol
from uuid import uuid4

import httpx
from mcp import ClientSession, StdioServerParameters
from mcp.client.sse import sse_client
from mcp.client.stdio import stdio_client
from openai.types.chat import ChatCompletionChunk

__version__ = "0.4.8"  # ä½ å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®ç‰ˆæœ¬å·


# openai.langfuse_auth_check()

# 1. å®šä¹‰å†…å­˜æ¥å£åè®®
class MemoryProtocol(Protocol):
    def store(self, data: str, user_id: str) -> Any:
        ...

    def retrieve(self, query: str, user_id: str) -> List[Any]:
        ...


class ToolRegistry:
    """é›†ä¸­ç®¡ç†å·¥å…·æ³¨å†Œè¡¨ï¼Œé¿å…å…¨å±€å˜é‡"""

    def __init__(self):
        self.function_mappings = {}  # å·¥å…·åç§° -> å·¥å…·å‡½æ•°
        self.function_info = {}  # å·¥å…·åç§° -> å·¥å…·infoä¿¡æ¯
        self.openai_function_schemas = []  # OpenAI æ ¼å¼çš„å·¥å…·æè¿°

    def register_tool(self, func: Callable) -> bool:
        """æ³¨å†Œå•ä¸ªå·¥å…·"""
        if not hasattr(func, "tool_info"):
            return False

        tool_info = func.tool_info
        tool_name = tool_info["tool_name"]

        # æ³¨å†Œåˆ°å­—å…¸
        self.function_info[tool_name] = tool_info
        self.function_mappings[tool_name] = func

        # æ„å»º OpenAI æ ¼å¼çš„å·¥å…·æè¿°
        tool_params_openai = {}
        tool_required = []
        for param in tool_info["tool_params"]:
            tool_params_openai[param["name"]] = {
                "type": param["type"],
                "description": param["description"],
            }
            if param["required"]:
                tool_required.append(param["name"])

        tool_def_openai = {
            "type": "function",
            "function": {
                "name": tool_name,
                "description": tool_info["tool_description"],
                "parameters": {
                    "type": "object",
                    "properties": tool_params_openai,
                    "required": tool_required,
                },
            }
        }

        self.openai_function_schemas.append(tool_def_openai)
        return True

    def register_tools(self, tools: List[Callable]) -> bool:
        """æ‰¹é‡æ³¨å†Œå·¥å…·"""
        success = True
        for func in tools:
            if not self.register_tool(func):
                success = False
        return success

    def get_tools(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å·¥å…·çš„æè¿°ï¼ˆOpenAI æ ¼å¼ï¼‰"""
        return deepcopy(self.openai_function_schemas)

    def get_tools_str(self) -> str:
        """å°†å·¥å…·æè¿°è½¬æ¢ä¸ºæ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²"""
        return json.dumps(self.openai_function_schemas, indent=4, ensure_ascii=False)

    def filter_tools(self, tool_reflection_result: str) -> List[Dict]:
        """æ ¹æ®å†…å®¹è¿‡æ»¤å·¥å…·"""
        try:
            # å®‰å…¨è§£æå¯èƒ½åŒ…å« Markdown ä»£ç å—çš„ JSON
            refined_content = tool_reflection_result.strip()
            if refined_content.startswith('```json') and refined_content.endswith('```'):
                refined_content = refined_content[7:-3].strip()

            parsed_data = json.loads(refined_content)
            valid_tools = {tool["name"].strip().lower() for tool in parsed_data.get("tools", [])}

            return [
                schema for schema in self.openai_function_schemas
                if isinstance(schema, dict) and
                   schema.get("function", {}).get("name", "").strip().lower() in valid_tools
            ]
        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            raise ValueError(f"å·¥å…·è¿‡æ»¤å¤±è´¥: {str(e)}") from e


class ToolLoader:
    """å·¥å…·åŠ è½½å™¨ï¼Œæ”¯æŒåŠ¨æ€åŠ è½½å’Œç¼“å­˜"""

    def __init__(self, tools_directory: str = "tools"):
        self.tools_directory = tools_directory
        self.loaded_tools = {}

    def load_tool(self, tool_name: str) -> Callable:
        """åŠ è½½å•ä¸ªå·¥å…·"""
        if tool_name in self.loaded_tools:
            return self.loaded_tools[tool_name]

        tool_path = os.path.join(self.tools_directory, f"{tool_name}.py")
        if not os.path.exists(tool_path):
            raise FileNotFoundError(f"Tool '{tool_name}' not found in {tool_path}")

        # åŠ¨æ€åŠ è½½æ¨¡å—
        spec = importlib.util.spec_from_file_location(tool_name, tool_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # è·å–å·¥å…·å‡½æ•°
        if hasattr(module, tool_name):
            tool_func = getattr(module, tool_name)
            if callable(tool_func) and hasattr(tool_func, "tool_info"):
                self.loaded_tools[tool_name] = tool_func
                return tool_func

        raise AttributeError(f"Tool '{tool_name}' is not properly defined in {tool_path}")

    def load_tools(self, tool_names: List[str]) -> Dict[str, Callable]:
        """æ‰¹é‡åŠ è½½å·¥å…·"""
        for tool_name in tool_names:
            if tool_name not in self.loaded_tools:
                self.load_tool(tool_name)
        return self.loaded_tools


class AsyncToolDispatcher:
    """å¼‚æ­¥å·¥å…·è°ƒåº¦å™¨"""

    async def dispatch(self, tool_name: str, tool_params: Dict[str, Any]) -> Union[
        str, Generator[str, None, None], AsyncGenerator[str, None]]:
        """è°ƒç”¨å·¥å…·æ‰§è¡Œï¼Œæ”¯æŒåŒæ­¥/å¼‚æ­¥å·¥å…·åŠæµå¼è¾“å‡º"""
        if tool_name not in self.function_mappings:
            return f"Tool `{tool_name}` not found."

        tool_call = self.function_mappings[tool_name]
        try:
            # å¤„ç†ä¸åŒç±»å‹çš„å·¥å…·
            if inspect.iscoroutinefunction(tool_call):
                result = await tool_call(**tool_params)
            elif inspect.isasyncgenfunction(tool_call):
                result = tool_call(**tool_params)
            else:
                result = tool_call(**tool_params)

            # å¤„ç†æµå¼è¾“å‡º
            if inspect.isasyncgen(result):
                return self.async_stream_generator(result)
            elif inspect.isgenerator(result):
                return self.stream_generator(result)
            return str(result)
        except Exception as e:
            return f"Tool call error: {str(e)}\n{traceback.format_exc()}"

    async def async_stream_generator(self, async_gen: AsyncGenerator) -> AsyncGenerator[str, None]:
        async for chunk in async_gen:
            yield chunk

    def stream_generator(self, sync_gen: Generator) -> Generator[str, None, None]:
        for chunk in sync_gen:
            yield chunk


class LoggerManager:
    """é›†ä¸­ç®¡ç†æ—¥å¿—ç³»ç»Ÿ"""

    def __init__(self, name: str, debug: bool, log_level: str, log_file: Optional[str] = None):
        self.name = name
        self.debug = debug
        self.logger = self._setup_logger(log_level, log_file)
        self.traceid = ""

    def _setup_logger(self, log_level: str, log_file: Optional[str] = None) -> logging.Logger:
        logger = logging.getLogger(self.name)
        logger.setLevel(log_level.upper())
        logger.propagate = False

        formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

        if self.debug:
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)

        if log_file:
            # ç¡®ä¿ log ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(log_file)
            if log_dir and not os.path.exists(log_dir):
                os.makedirs(log_dir)

            file_handler = logging.FileHandler(log_file)
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)

        return logger

    def log(self, level: str, action: str, data: Any):
        """è®°å½•æ—¥å¿—"""
        if not self.debug:
            return

        trace_info = f"[TraceID: {self.traceid}] " if self.traceid else ""
        log_message = f"{trace_info}{action}: {data}"
        safe_msg = log_message.encode('utf-8', 'ignore').decode('utf-8')

        if level == "DEBUG":
            self.logger.debug(safe_msg)
        elif level == "INFO":
            self.logger.info(safe_msg)
        elif level == "ERROR":
            self.logger.error(safe_msg)

    def set_traceid(self, traceid: str):
        """è®¾ç½®å½“å‰è·Ÿè¸ªID"""
        self.traceid = traceid


class MCPClientManager:
    """å¢å¼ºç‰ˆMCPå®¢æˆ·ç«¯ç®¡ç†å™¨"""

    def __init__(self, config: dict, tool_registry: ToolRegistry):
        self.config = config
        self.tool_registry = tool_registry
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.server_sessions = {}

    async def _create_session(self, server_name: str, config: dict):
        """åˆ›å»ºå¹¶ç®¡ç†ä¼šè¯ä¸Šä¸‹æ–‡"""
        if 'url' in config:
            # SSE æœåŠ¡å™¨è¿æ¥
            streams_context = sse_client(
                url=config['url'],
                headers=config.get('headers', {})
            )
            streams = await self.exit_stack.enter_async_context(streams_context)
            session_context = ClientSession(*streams)
            self.session = await self.exit_stack.enter_async_context(session_context)
        else:
            # æ ‡å‡†è¾“å…¥è¾“å‡ºæœåŠ¡å™¨è¿æ¥
            server_params = StdioServerParameters(
                command=config["command"],
                args=config["args"],
                env=config.get("env")
            )
            transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
            stdio, write = transport
            session_context = ClientSession(stdio, write)
            self.session = await self.exit_stack.enter_async_context(session_context)

        await self.session.initialize()
        self.server_sessions[server_name] = self.session

    async def cleanup(self):
        """æ¸…ç†æ‰€æœ‰ä¼šè¯èµ„æº"""
        await self.exit_stack.aclose()
        self.server_sessions.clear()

    async def register_mcp_tool(self) -> bool:
        """è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰MCPæœåŠ¡çš„å·¥å…·"""
        registered_count = 0
        enabled_servers = [
            (name, config)
            for name, config in self.config["mcpServers"].items()
            if not config["disabled"]
        ]

        for server_name, config in enabled_servers:
            try:
                await self._create_session(server_name, config)
                tools_response = await self.session.list_tools()
                print(f"ğŸ” Registering MCP tools for server : {server_name} ...")

                for tool in tools_response.tools:
                    try:
                        # æ„å»ºå·¥å…·å…ƒæ•°æ®
                        tool_info = {
                            "tool_name": tool.name,
                            "tool_description": tool.description,
                            "tool_params": []
                        }

                        # è§£æå‚æ•°æ¨¡å¼
                        properties = tool.inputSchema.get("properties", {})
                        required_fields = tool.inputSchema.get("required", [])

                        for param_name, param_schema in properties.items():
                            tool_info["tool_params"].append({
                                "name": param_name,
                                "type": param_schema.get("type", "string"),
                                "description": param_schema.get("title", ""),
                                "required": param_name in required_fields
                            })

                        # æ³¨å†Œåˆ°å·¥å…·æ³¨å†Œè¡¨
                        self.tool_registry.function_info[tool.name] = tool_info
                        self.tool_registry.function_mappings[tool.name] = partial(
                            self._call_tool_wrapper,
                            tool_name=tool.name,
                            target_server=server_name
                        )

                        # æ„å»ºOpenAIæ ¼å¼
                        openai_schema = {
                            "type": "function",
                            "function": {
                                "name": tool.name,
                                "description": tool.description,
                                "parameters": {
                                    "type": "object",
                                    "properties": {
                                        k: {"type": v["type"], "description": v.get("title", "")}
                                        for k, v in properties.items()
                                    },
                                    "required": required_fields
                                }
                            }
                        }
                        self.tool_registry.openai_function_schemas.append(openai_schema)
                        registered_count += 1
                        print(f"âœ… The registered MCP tool : {tool.name}")
                    except Exception as e:
                        continue
            except Exception as e:
                continue

        await self.cleanup()
        return registered_count > 0

    async def _call_tool_wrapper(self, tool_name: str, target_server: str, **kwargs):
        """å‚æ•°è½¬æ¢é€‚é…å™¨"""
        return await self.call_tool(
            tool_name=tool_name,
            arguments=kwargs,
            target_server=target_server
        )

    async def call_tool(self, tool_name: str, arguments: dict, target_server: str = None):
        """é€šç”¨å·¥å…·è°ƒç”¨æ–¹æ³•"""
        enabled_servers = [
            (name, config)
            for name, config in self.config["mcpServers"].items()
            if not config["disabled"]
        ]

        if target_server:
            enabled_servers = [s for s in enabled_servers if s[0] == target_server]

        for server_name, config in enabled_servers:
            try:
                session = self.server_sessions.get(server_name)
                if not session:
                    await self._create_session(server_name, config)
                    session = self.session

                tools = await session.list_tools()
                available_tools = {t.name: t for t in tools.tools}

                if tool_name in available_tools:
                    # éªŒè¯å‚æ•°ç±»å‹
                    schema = available_tools[tool_name].inputSchema
                    self._validate_arguments(arguments, schema)

                    # æ‰§è¡Œè°ƒç”¨
                    result = await session.call_tool(tool_name, arguments)
                    await self.cleanup()
                    return {
                        "server": server_name,
                        "tool": tool_name,
                        "result": result.content[0].text
                    }
            except Exception as e:
                continue

        raise ValueError(f"å·¥å…· {tool_name} åœ¨å¯ç”¨æœåŠ¡å™¨ä¸­æœªæ‰¾åˆ°")

    def _validate_arguments(self, arguments: dict, schema: dict):
        """ç®€å•å‚æ•°æ ¡éªŒ"""
        required_fields = schema.get("required", [])
        for field in required_fields:
            if field not in arguments:
                raise ValueError(f"ç¼ºå°‘å¿…è¦å‚æ•°: {field}")


class LightAgent:
    __version__ = "0.4.8"  # å°†ç‰ˆæœ¬å·æ”¾åœ¨ç±»ä¸­

    def __init__(
            self,
            *,
            name: Optional[str] = None,  # ä»£ç†åç§°
            instructions: Optional[str] = None,  # ä»£ç†æŒ‡ä»¤
            role: Optional[str] = None,  # ä»£ç†è§’è‰²
            model: str,  # agentæ¨¡å‹åç§°
            api_key: str | None = None,  # æ¨¡å‹ api key
            base_url: str | httpx.URL | None = None,  # æ¨¡å‹ base url
            websocket_base_url: str | httpx.URL | None = None,  # æ¨¡å‹ websocket base url
            memory: Optional[MemoryProtocol] = None,  # æ”¯æŒå¤–éƒ¨ä¼ å…¥è®°å¿†æ¨¡å—
            tree_of_thought: bool = False,  # æ˜¯å¦å¯ç”¨é“¾å¼æ€è€ƒ
            tot_model: str | None = None,  # é“¾å¼æ€è€ƒæ¨¡å‹
            tot_api_key: str | None = None,  # é“¾å¼æ€è€ƒæ¨¡å‹APIå¯†é’¥
            tot_base_url: str | httpx.URL | None = None,  # é“¾å¼æ€è€ƒæ¨¡å‹base_url
            filter_tools: bool = True,  # æ˜¯å¦å¯ç”¨å·¥å…·è¿‡æ»¤
            self_learning: bool = False,  # æ˜¯å¦å¯ç”¨agentè‡ªæˆ‘å­¦ä¹ 
            tools: List[Union[str, Callable]] = None,  # æ”¯æŒå·¥å…·æ··åˆè¾“å…¥
            debug: bool = False,  # æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
            log_level: str = "INFO",  # æ—¥å¿—çº§åˆ«ï¼ˆINFO, DEBUG, ERRORï¼‰
            log_file: Optional[str] = None,  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
            tracetools: Optional[dict] = None,  # logè·Ÿè¸ªå·¥å…·
    ) -> None:
        """
        åˆå§‹åŒ– LightAgentã€‚

        :param name: ä»£ç†åç§°ã€‚
        :param instructions: ä»£ç†æŒ‡ä»¤ã€‚
        :param role: Agent çš„è§’è‰²æè¿°ã€‚
        :param model: ä½¿ç”¨çš„æ¨¡å‹åç§°ã€‚
        :param api_key: API å¯†é’¥ã€‚
        :param base_url: API çš„åŸºç¡€ URLã€‚
        :param websocket_base_url: WebSocket çš„åŸºç¡€ URLã€‚
        :param memory: å¤–éƒ¨ä¼ å…¥çš„è®°å¿†æ¨¡å—ï¼Œéœ€å®ç° `retrieve` å’Œ `store` æ–¹æ³•ã€‚
        :param tree_of_thought: æ˜¯å¦å¯ç”¨æ€ç»´é“¾åŠŸèƒ½ã€‚
        :param tot_model: ä½¿ç”¨çš„æ¨¡å‹åç§°ã€‚
        :param tot_api_key: API å¯†é’¥ã€‚
        :param tot_base_url: API çš„åŸºç¡€ URLã€‚
        :param filter_tools: æ˜¯å¦å¯ç”¨å·¥å…·è¿‡æ»¤ã€‚
        :param tools: å·¥å…·åˆ—è¡¨ï¼Œæ”¯æŒå‡½æ•°åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–å‡½æ•°å¯¹è±¡ã€‚
        :param debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ã€‚
        :param log_level: æ—¥å¿—çº§åˆ«ï¼ˆINFO, DEBUG, ERRORï¼‰ã€‚
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ã€‚
        :param tracetools: logè·Ÿè¸ªå·¥å…·ã€‚
        """

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.tool_registry = ToolRegistry()
        self.tool_loader = ToolLoader()
        self.tool_dispatcher = AsyncToolDispatcher()
        self.tool_dispatcher.function_mappings = self.tool_registry.function_mappings

        self.mcp_setting = None
        self.mcp_client = None
        if not model:
            model = "gpt-4o-mini"  # é»˜è®¤æ¨¡å‹
        if not api_key:
            api_key = os.environ.get("OPENAI_API_KEY")
        if not base_url:
            base_url = os.environ.get("OPENAI_BASE_URL")
        self.loaded_tools = {}  # ç”¨äºå­˜å‚¨å·²åŠ è½½çš„å·¥å…·å‡½æ•°
        if not name:
            random_suffix = random.randint(10000000, 99999999)  # ç”Ÿæˆä¸€ä¸ª8ä½éšæœºæ•°ä½œä¸ºagentç¼–å·
            name = f"LightAgent{random_suffix}"
        self.name = name
        if not instructions:
            instructions = "You are a helpful agent."
        self.instructions = instructions
        self.role = role
        self.model = model
        self.memory = memory
        self.tree_of_thought = tree_of_thought
        self.self_learning = self_learning
        self.filter_tools = filter_tools

        self.debug = debug
        self.log_level = log_level.upper()
        self.traceid = ""  # ç”¨äºå­˜å‚¨ traceid
        # ç¡®ä¿ log ç›®å½•å­˜åœ¨
        log_dir = 'logs'
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
        # å°† log_file è·¯å¾„è®¾ç½®ä¸º log ç›®å½•ä¸‹çš„æ–‡ä»¶
        if debug:
            self.log_file = os.path.join(log_dir, log_file)
            # Set up the logger
            # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
            self.logger = LoggerManager(
                name=self.name,
                debug=debug,
                log_level=log_level,
                log_file=log_file
            )

        if tools is None:
            self.tools = []
        if tools:
            self.tools = tools
            # åˆå§‹åŒ–å·¥å…·åˆ—è¡¨
            self.load_tools(tools)
            # register_tool_manually(tools)

        if api_key is None:
            raise ValueError(
                "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
            )
        self.api_key = api_key
        self.websocket_base_url = websocket_base_url
        self.base_url = base_url or os.environ.get("OPENAI_BASE_URL") or "https://api.openai.com/v1"

        if self.tree_of_thought:
            if tot_api_key is None:
                tot_api_key = self.api_key
            if tot_base_url is None:
                tot_base_url = self.base_url
            if not tot_model:
                tot_model = "deepseek-r1"  # é»˜è®¤æ€ç»´æ¨ç†æ¨¡å‹ä¸ºdeepseek-r1
            self.tot_model = tot_model

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self._initialize_clients(tracetools, tot_api_key, tot_base_url, tot_model)
        self.chat_params = {}  # history å­˜å‚¨å™¨

    def _initialize_clients(self, tracetools, tot_api_key, tot_base_url, tot_model):
        """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        if tracetools:
            from langfuse.openai import openai as la_openai
            la_openai.langfuse_public_key = tracetools['TraceToolConfig']['langfuse_public_key']
            la_openai.langfuse_secret_key = tracetools['TraceToolConfig']['langfuse_secret_key']
            la_openai.langfuse_enabled = tracetools['TraceToolConfig']['langfuse_enabled']
            la_openai.langfuse_host = tracetools['TraceToolConfig']['langfuse_host']
            la_openai.base_url = self.base_url
            la_openai.api_key = self.api_key
            self.client = la_openai

            if self.tree_of_thought:
                la_openai.base_url = tot_base_url or self.base_url
                la_openai.api_key = tot_api_key or self.api_key
                self.tot_client = la_openai
        else:
            from openai import OpenAI as la_openai
            self.client = la_openai(
                base_url=self.base_url,
                api_key=self.api_key
            )
            if self.tree_of_thought:
                self.tot_client = la_openai(
                    base_url=tot_base_url or self.base_url,
                    api_key=tot_api_key or self.api_key
                )

    def get_history(self) -> List[Dict[str, Any]]:
        """
        è·å–å¯¹è¯çš„historyçš„æè¿°ï¼ˆOpenAI æ ¼å¼ï¼‰
        """
        return deepcopy(self.chat_params['messages'])

    def get_tools(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰å·¥å…·çš„æè¿°ï¼ˆOpenAI æ ¼å¼ï¼‰
        """
        return deepcopy(self.tool_registry.get_tools())

    def get_tool(self, tool_name: str) -> Callable:
        """
        ç”¨äºå¤–éƒ¨å¯ä»¥è·å–å·²åŠ è½½çš„å·¥å…·å‡½æ•°
        :param tool_name: å·¥å…·åç§°
        :return: å·¥å…·å‡½æ•°
        """
        if tool_name in self.loaded_tools:
            return self.loaded_tools[tool_name]
        raise ValueError(f"Tool `{tool_name}` is not loaded.")

    def load_tools(self, tool_names: List[Union[str, Callable]], tools_directory: str = "tools"):
        """åŠ è½½å¹¶æ³¨å†Œå·¥å…·"""
        for tool in tool_names:
            if isinstance(tool, str):
                try:
                    tool_func = self.tool_loader.load_tool(tool)
                    self.tool_registry.register_tool(tool_func)
                    self.loaded_tools[tool] = tool_func
                    self.log("DEBUG", "load_tools", {"tool": tool, "status": "success"})
                except Exception as e:
                    self.log("ERROR", "load_tools", {"tool": tool, "error": str(e)})
            elif callable(tool) and hasattr(tool, "tool_info"):
                if self.tool_registry.register_tool(tool):
                    tool_name = tool.tool_info.get("tool_name") or tool.__name__
                    self.loaded_tools[tool_name] = tool
                    self.log("DEBUG", "register_tool", {"tool": tool.__name__, "status": "success"})

    async def setup_mcp(
            self,
            mcp_setting: dict | None = None,  # mcp è®¾ç½®
    ):
        if mcp_setting:
            self.mcp_setting = mcp_setting
        """å•ç‹¬åˆå§‹åŒ– MCP æ¨¡å—"""
        if self.mcp_setting and not self.mcp_client:
            self.mcp_client = MCPClientManager(self.mcp_setting, self.tool_registry)
            await self.mcp_client.register_mcp_tool()
            self.log("INFO", "setup_mcp", "MCP æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")

    def log(self, level, action, data):
        """
        æ—¥å¿—æ‰“å°å…¥å£
        """
        if not self.debug:
            return
        self.logger.log(level, action, data)

    def run(
            self,
            query: str,
            tools: List[Union[str, Callable]] | None = None,  # è¿è¡Œæ—¶ä¼ å…¥çš„å·¥å…·
            light_swarm=None,
            stream: bool = False,
            max_retry: int = 10,
            user_id: str = "default_user",
            history: list = None,
            metadata: Optional[Dict] = None,
    ) -> Union[Generator[str, None, None], str]:
        """
        è¿è¡Œä»£ç†ï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥ã€‚

        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :param tools: è¿è¡Œæ—¶ä¼ å…¥çš„å·¥å…·åˆ—è¡¨ï¼Œæ”¯æŒå‡½æ•°åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–å‡½æ•°å¯¹è±¡ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ï¼Œç”¨äºä»»åŠ¡è½¬ç§»ã€‚
        :param stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºã€‚
        :param max_retry: æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚
        :param user_id: ç”¨æˆ· IDã€‚
        :param history: å†å²å¯¹è¯ ã€‚
        :param metadata: å…ƒæ•°æ®ã€‚
        :return: ä»£ç†çš„å›å¤ã€‚
        """
        # è®¾ç½®è·Ÿè¸ªID
        traceid = uuid4().hex
        if self.debug and hasattr(self, 'logger'):  # ä»…åœ¨ debug=True ä¸” logger å­˜åœ¨æ—¶è®°å½•æ—¥å¿—
            self.logger.set_traceid(traceid)
        self.log("INFO", "run_start", {"query": query, "user_id": user_id, "stream": stream})

        # åˆå§‹åŒ–å†å²è®°å½•
        history = history or []

        # å¤„ç†è¿è¡Œæ—¶ä¼ å…¥çš„å·¥å…·
        runtime_tools = []
        if tools:
            runtime_tools = self._process_runtime_tools(tools)

        # 0. åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬ç§»ä»»åŠ¡
        if light_swarm:
            result = self._handle_task_transfer(query, light_swarm, stream)
            if result is not None:
                return result

        # 1. æ­£å¸¸å¤„ç†ä»»åŠ¡
        now = datetime.now()
        current_date = now.strftime("%Y-%m-%d")
        current_time = now.strftime("%H:%M:%S")
        system_prompt = (
            f"##ä»£ç†åç§°ï¼š{self.name}\n"
            f"##ä»£ç†æŒ‡ä»¤ï¼š{self.instructions}\n"
            f"##èº«ä»½ï¼š{self.role}\n"
            f"è¯·ä¸€æ­¥ä¸€æ­¥æ€è€ƒæ¥å®Œæˆç”¨æˆ·çš„è¦æ±‚ã€‚å°½å¯èƒ½å®Œæˆç”¨æˆ·çš„å›ç­”ï¼Œå¦‚æœæœ‰è¡¥å……ä¿¡æ¯ï¼Œè¯·å‚è€ƒè¡¥å……ä¿¡æ¯æ¥è°ƒç”¨å·¥å…·ï¼Œç›´åˆ°è·å–æ‰€æœ‰æ»¡è¶³ç”¨æˆ·çš„æé—®æ‰€éœ€çš„ç­”æ¡ˆã€‚\n"
            f"ä»Šæ—¥çš„æ—¥æœŸ: {current_date} å½“å‰æ—¶é—´: {current_time}"
        )
        # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
        query = self._add_memory_context(query, user_id)

        # æ€ç»´é“¾å¤„ç†
        active_tools = []
        if self.tree_of_thought:
            tot_response, active_tools = self.run_thought(query, runtime_tools)
            system_prompt += f"\n##ä»¥ä¸‹æ˜¯é—®é¢˜çš„è¡¥å……è¯´æ˜\n{tot_response}"
            self.log("DEBUG", "tree_of_thought", {"response": tot_response, "active_tools": active_tools})
        # å¦‚æœæ²¡æœ‰å¯ç”¨æ€ç»´é“¾ä¸”æœ‰è¿è¡Œæ—¶å·¥å…·ï¼Œåˆ™ä½¿ç”¨è¿è¡Œæ—¶å·¥å…·
        elif runtime_tools:
            active_tools = runtime_tools
            self.log("DEBUG", "use_runtime_tools", {"runtime_tools": runtime_tools})

        # åœ¨ç”¨æˆ·æŸ¥è¯¢åè¿½åŠ  "no_think"
        # modified_query = query + "/no_think"
        # å‡†å¤‡APIå‚æ•°
        self.chat_params = {
            "model": self.model,
            "messages": [{"role": "system", "content": system_prompt}] + history + [
                {"role": "user", "content": query}],
            "stream": stream
        }

        # æ·»åŠ å‚æ•°
        if metadata:
            for key, value in metadata.items():
                self.chat_params[key] = value

        # æ·»åŠ å·¥å…·
        # ä¼˜å…ˆçº§ï¼šactive_tools > runtime_tools > åˆå§‹åŒ–æ—¶çš„å·¥å…·
        final_tools = []
        if active_tools:
            final_tools = active_tools
        elif runtime_tools:
            final_tools = runtime_tools
        else:
            final_tools = self.tool_registry.get_tools()

        if final_tools:
            self.chat_params["tools"] = final_tools
            self.chat_params["tool_choice"] = "auto"
            self.log("DEBUG", "final_tools_selected",
                     {"tools": [t.get("function", {}).get("name", str(t)) for t in final_tools]})

        # æ·»åŠ è·Ÿè¸ªä¼šè¯
        if hasattr(self, 'tracetools') and self.tracetools:
            self.chat_params["session_id"] = traceid

        # è°ƒç”¨æ¨¡å‹
        self.log("DEBUG", "first_request_params", {"params": self.chat_params})
        response = self.client.chat.completions.create(**self.chat_params)
        return self._core_run_logic(response, stream, max_retry)

    def _process_runtime_tools(self, tools: List[Union[str, Callable]]) -> List[Dict]:
        """
        å¤„ç†è¿è¡Œæ—¶ä¼ å…¥çš„å·¥å…·ï¼Œè¿”å›OpenAIæ ¼å¼çš„å·¥å…·æè¿°

        :param tools: è¿è¡Œæ—¶ä¼ å…¥çš„å·¥å…·åˆ—è¡¨
        :return: OpenAIæ ¼å¼çš„å·¥å…·æè¿°åˆ—è¡¨
        """
        runtime_tools = []
        temp_registry = ToolRegistry()

        for tool in tools:
            if isinstance(tool, str):
                try:
                    tool_func = self.tool_loader.load_tool(tool)
                    temp_registry.register_tool(tool_func)
                except Exception as e:
                    self.log("ERROR", "load_runtime_tool", {"tool": tool, "error": str(e)})
            elif callable(tool) and hasattr(tool, "tool_info"):
                temp_registry.register_tool(tool)

        runtime_tools = temp_registry.get_tools()
        self.log("DEBUG", "runtime_tools_processed", {"count": len(runtime_tools)})
        return runtime_tools

    def _add_memory_context(self, query: str, user_id: str) -> str:
        """æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡"""
        if not self.memory:
            return query

        context = ""
        related_memories = self.memory.retrieve(query=query, user_id=user_id)
        if related_memories and related_memories.get("results"):
            context += "\n##ç”¨æˆ·åå¥½\nç”¨æˆ·ä¹‹å‰æåˆ°äº†:\n" + "\n".join(
                [m["memory"] for m in related_memories["results"]]
            )
        self.memory.store(data=query, user_id=user_id)

        if self.self_learning:
            agent_memories = self.memory.retrieve(query=query, user_id=self.name)
            if agent_memories and agent_memories.get("results"):
                context += "\n##é—®é¢˜ç›¸å…³è¡¥å……ä¿¡æ¯:\n" + "\n".join(
                    [m["memory"] for m in agent_memories["results"]]
                )
            self.memory.store(data=query, user_id=self.name)

        return f"{context}\n##ç”¨æˆ·æé—®ï¼š\n{query}" if context else query

    def _core_run_logic(self, response, stream, max_retry) -> Union[Generator[str, None, None], str]:
        """æ ¸å¿ƒè¿è¡Œé€»è¾‘"""
        if stream:
            return self._run_stream_logic(response, max_retry)
        else:
            return self._run_non_stream_logic(response, max_retry)

    def _run_non_stream_logic(self, response, max_retry) -> Union[str, None]:
        """
        éæµå¼å¤„ç†é€»è¾‘ã€‚
        """
        for _ in range(max_retry):
            if response.choices[0].message.tool_calls:
                # åˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœ
                tool_responses = []
                # åˆå§‹åŒ–å˜é‡
                output = ""
                function_call_name = ""
                tool_calls = response.choices[0].message.tool_calls
                self.log("DEBUG", "non_stream tool_calls", {"tool_calls": tool_calls})

                # éå†æ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in tool_calls:
                    function_call = tool_call.function

                    # å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§è½¬ä¹‰é—®é¢˜
                    fixed_args = function_call.arguments.replace('\\"', '"').replace('\\\\', '\\')
                    self.log("DEBUG", "non_stream function_call", {"function_call": fixed_args})

                    # è§£æå‡½æ•°å‚æ•°
                    function_args = json.loads(fixed_args)

                    # è°ƒç”¨å·¥å…·å¹¶è·å–å“åº”
                    tool_response = asyncio.run(self.tool_dispatcher.dispatch(function_call.name, function_args))
                    function_call_name = function_call.name
                    combined_response = ""
                    single_tool_response = ""

                    # å¦‚æœå·¥å…·è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼Œåˆ™å°†æ‰€æœ‰ chunk å åŠ 
                    if isinstance(tool_response, Generator):
                        # print(f"Streaming response from tool: {function_call.name}")
                        for chunk in tool_response:
                            # print("Received chunk:", chunk)  # æ‰“å°æ¯ä¸ª chunk
                            if function_call_name == 'finish':
                                content = chunk.choices[0].delta.content or ""
                                combined_response += content  # å°†æ¯ä¸ª chunk å åŠ 
                            else:
                                combined_response += chunk  # å°†æ¯ä¸ª chunk å åŠ 
                        if combined_response == "":
                            combined_response = "".join(tool_response)

                        # å°† combined_response è§£æä¸º JSON å¯¹è±¡ï¼ˆå¦‚æœå®ƒæ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
                        try:
                            combined_response = json.loads(combined_response)  # è§£æ JSON
                        except json.JSONDecodeError:
                            pass  # å¦‚æœä¸æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œä¿æŒåŸæ ·

                        # å°† JSON å¯¹è±¡ä¸­çš„ Unicode ç¼–ç è½¬æ¢ä¸ºä¸­æ–‡å­—ç¬¦
                        if isinstance(combined_response, dict):
                            combined_response = json.dumps(combined_response, ensure_ascii=False)  # ç¡®ä¿ä¸­æ–‡å­—ç¬¦ä¸è½¬ä¹‰
                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•

                    else:
                        # print(f"Non-streaming response from tool: {function_call.name}")
                        combined_response = tool_response
                        # print("tool_response type:",type(combined_response))
                        # å¦‚æœæ˜¯ JSON å­—ç¬¦ä¸²ï¼Œè§£æå¹¶è½¬æ¢ä¸ºä¸­æ–‡
                        if isinstance(combined_response, str):
                            try:
                                combined_response = json.loads(combined_response)  # è§£æ JSON
                                combined_response = json.dumps(combined_response, ensure_ascii=False)  # è½¬æ¢ä¸ºä¸­æ–‡
                            except json.JSONDecodeError:
                                combined_response = tool_response
                                pass  # å¦‚æœä¸æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œä¿æŒåŸæ ·
                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•

                    self.log("INFO", "non_stream single_tool_response",
                             {"single_tool_response": single_tool_response})

                    # å°†å•ä¸ªå·¥å…·çš„å“åº”ç»“æœæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    tool_responses.append(single_tool_response)

                # å°†æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœåˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
                self.log("DEBUG", "non_stream tool_responses", {"tool_responses": tool_responses})

                combined_tool_response = "\n".join(tool_responses)

                # å°†å·¥å…·è°ƒç”¨å’Œå“åº”æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
                self.chat_params["messages"].append(
                    {
                        "role": "assistant",
                        "content": f"ä½¿ç”¨å·¥å…·ï¼š \n {json.dumps([tool_call.function.model_dump() for tool_call in tool_calls], ensure_ascii=False)}\n",
                    }
                )
                self.chat_params["messages"].append(
                    {
                        "role": "user",
                        "content": f"å·¥å…·å“åº”å†…å®¹ï¼š\n {combined_tool_response} \n è¯·ç»™å‡ºä¸‹ä¸€æ­¥è¾“å‡º",
                    }
                )
            else:
                # è¿”å›æœ€ç»ˆå›å¤
                reply = response.choices[0].message.content
                self.log("INFO", "non_stream final_reply", {"reply": reply})
                return reply

            # æ›´æ–°å“åº”
            if function_call_name == 'finish':
                return  # å¦‚æœæœ€åè°ƒç”¨äº†finishå·¥å…·ï¼Œåˆ™ç»“æŸç”Ÿæˆå™¨
            # print("params:",self.chat_params)
            self.log("DEBUG", "non_stream chat-completions params", {"params": self.chat_params})

            try:
                response = self.client.chat.completions.create(**self.chat_params)
            except Exception as e:
                print(f"An error occurred: {e}")

        # é‡è¯•æ¬¡æ•°ç”¨å°½
        self.log("ERROR", "max_retry_reached", {"message": "Failed to generate a valid response."})
        return "Failed to generate a valid response."

    def _run_stream_logic(self, response, max_retry) -> Generator[str, None, None]:
        """æµå¼å¤„ç†é€»è¾‘"""
        for _ in range(max_retry):
            # åˆå§‹åŒ–å˜é‡
            output = ""
            tool_calls = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ä¿¡æ¯
            tool_responses = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœ
            finish_called = False  # æ ‡è®°æ˜¯å¦è°ƒç”¨äº†finishå·¥å…·
            reasoning_content = ""
            content = ""

            for chunk in response:

                if chunk.choices and len(chunk.choices) > 0:
                    choice = chunk.choices[0]

                if choice and hasattr(choice.delta, "reasoning_content") and choice.delta.reasoning_content is not None:
                    reasoning_content = choice.delta.reasoning_content or ""

                if reasoning_content:
                    output += reasoning_content

                if choice and hasattr(choice.delta, "content") and choice.delta.content is not None:
                    content = choice.delta.content or ""

                if content:
                    output += content

                yield chunk  # æµå¼è¿”å›å†…å®¹

                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if chunk.choices and chunk.choices[0].delta.tool_calls:
                        tool_call_delta = chunk.choices[0].delta.tool_calls[0]

                        # è·å–å·¥å…·è°ƒç”¨çš„ç´¢å¼•ï¼Œç¡®ä¿å®ƒæ˜¯æœ‰æ•ˆçš„æ•´æ•°
                        tool_call_index = tool_call_delta.index if hasattr(tool_call_delta,
                                                                           "index") and tool_call_delta.index is not None else 0

                        # å¦‚æœå·¥å…·è°ƒç”¨ä¿¡æ¯å°šæœªè®°å½•ï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºå­—å…¸
                        if len(tool_calls) <= tool_call_index:
                            tool_calls.append({"name": "", "arguments": "", "index": tool_call_index, "title": ""})

                        # æ›´æ–°å·¥å…·è°ƒç”¨çš„åç§°
                        if hasattr(tool_call_delta.function, "name") and tool_call_delta.function.name:
                            tool_calls[tool_call_index]["name"] = tool_call_delta.function.name

                        # æ›´æ–°å·¥å…·è°ƒç”¨çš„å‚æ•°
                        if hasattr(tool_call_delta.function, "arguments") and tool_call_delta.function.arguments:
                            tool_calls[tool_call_index]["arguments"] += tool_call_delta.function.arguments

                except (IndexError, AttributeError, KeyError) as e:
                    self.log("ERROR", "tool_call_error", {
                        "error": str(e),
                        "traceback": traceback.format_exc()
                    })

                # å¦‚æœæµå¼è¾“å‡ºç»“æŸ
                finish_reason = chunk.choices[0].finish_reason if chunk.choices else None
                if finish_reason == "stop" and not any(tc["name"] for tc in tool_calls):
                    self.log("INFO", "stream_response", {"output": output})
                    return  # ç»“æŸç”Ÿæˆå™¨

                # å¦‚æœå·¥å…·è°ƒç”¨ç»“æŸ
                elif finish_reason in ("tool_calls", "stop") and any(tc["name"] for tc in tool_calls):
                    # éå†æ‰€æœ‰å·¥å…·è°ƒç”¨
                    self.log("DEBUG", "stream tool_calls", {"tool_calls": tool_calls})
                    for tool_call in tool_calls:
                        if tool_call["name"]:  # ç¡®ä¿å·¥å…·è°ƒç”¨æœ‰åç§°
                            tool_name = tool_call["name"]
                            arguments = tool_call["arguments"]

                            # ä»æ³¨å†Œè¡¨ä¸­è·å–å·¥å…·æ ‡é¢˜
                            tool_info = self.tool_registry.function_info.get(tool_name, {})
                            tool_title = tool_info.get("tool_title") or ""

                            # æ›´æ–°å·¥å…·è°ƒç”¨ä¿¡æ¯
                            tool_call["title"] = tool_title

                            # è®°å½•è°ƒç”¨å·¥å…·
                            tool_call_info = {
                                "name": tool_name,
                                "title": tool_title,
                                "arguments": arguments,
                            }
                            self.log("INFO", "stream function_call", {"tool_call_start": tool_call_info})
                            # å°†å·¥å…·çš„è°ƒç”¨ä¿¡æ¯æ¨é€ç»™å¼€å‘è€…
                            yield tool_call_info

                            # è§£æå‚æ•°å¹¶è°ƒç”¨å·¥å…·
                            try:
                                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å°†å¤šä¸ª JSON å¯¹è±¡æ‹†åˆ†å¼€
                                json_objects = re.findall(r'\{.*?\}', tool_call_info["arguments"])

                                # è§£ææ¯ä¸ª JSON å¯¹è±¡å¹¶è°ƒç”¨å·¥å…·
                                # for json_obj in json_objects:
                                #     function_args = json.loads(json_obj)
                                #     tool_response = dispatch_tool(function_call["name"], function_args)
                                #     tool_responses.append(tool_response)

                                for json_obj in json_objects:
                                    # å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§è½¬ä¹‰é—®é¢˜
                                    fixed_args = json_obj.replace('\\"', '"').replace('\\\\', '\\')
                                    self.log("DEBUG", "stream fixed_args", {"fixed_args": fixed_args})

                                    # è§£æå‚æ•°
                                    function_args = json.loads(fixed_args)

                                    # è°ƒç”¨å·¥å…·
                                    tool_response = asyncio.run(self.tool_dispatcher.dispatch(tool_name, function_args))

                                    # å¤„ç†ä¸åŒç±»å‹çš„å·¥å…·å“åº”
                                    combined_response = ""
                                    single_tool_response = ""

                                    # å¦‚æœå·¥å…·è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼Œåˆ™å°†æ‰€æœ‰ chunk å åŠ 
                                    if isinstance(tool_response, Generator):
                                        # print(f"Streaming response from tool: {function_call['name']}")
                                        for chunk in tool_response:
                                            # å°†å·¥å…·è¿”å›çš„æ•°æ®ç»§ç»­æµå‡º
                                            if isinstance(chunk, ChatCompletionChunk):
                                                yield chunk
                                            else:
                                                tool_output = {
                                                    "name": tool_name,
                                                    "title": tool_title,
                                                    "output": chunk,
                                                }
                                                self.log("DEBUG", "stream tool_output",
                                                         {"tool_output": tool_output})
                                                yield tool_output
                                            # å°†å·¥å…·çš„è°ƒç”¨ä¿¡æ¯æ¨é€ç»™å¼€å‘è€…
                                            if tool_name == 'finish':
                                                content = chunk.choices[0].delta.content or ""
                                                combined_response += content  # å°†æ¯ä¸ª chunk å åŠ 
                                            else:
                                                combined_response += chunk  # å°†æ¯ä¸ª chunk å åŠ 
                                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•
                                    else:
                                        # print(f"Non-streaming response from tool: {tool_response}")
                                        combined_response = str(tool_response)
                                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•
                                        tool_output = {
                                            "name": tool_name,
                                            "title": tool_title,
                                            "output": combined_response
                                        }
                                        yield tool_output

                                    # è®°å½•å·¥å…·å“åº”
                                    self.log("INFO", "stream single_tool_response",
                                             {"single_tool_response": single_tool_response})

                                    # å°†å•ä¸ªå·¥å…·çš„å“åº”ç»“æœä¿å­˜åˆ°åˆ—è¡¨ä¸­
                                    tool_responses.append(single_tool_response)

                                    # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†finishå·¥å…·
                                    if tool_name == 'finish':
                                        finish_called = True
                                        self.log("INFO", "finish_tool_called", {"response": combined_response})

                            except json.JSONDecodeError as e:
                                error_msg = f"JSONè§£æé”™è¯¯: {str(e)}\nå‚æ•°: {arguments}"
                                self.log("ERROR", "json_decode_error",
                                         {"tool": tool_name, "title": tool_title, "error": error_msg})
                                tool_responses.append(error_msg)
                                yield {"name": tool_name, "title": tool_title, "error": error_msg}

                            except Exception as e:
                                error_msg = f"å·¥å…·è°ƒç”¨é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
                                self.log("ERROR", "tool_execution_error", {
                                    "tool": tool_name,
                                    "title": tool_title,
                                    "error": error_msg
                                })
                                tool_responses.append(error_msg)
                                yield {"name": tool_name, "title": tool_title, "error": error_msg}

                    # å¦‚æœè°ƒç”¨äº†finishå·¥å…·ï¼Œåˆ™ç»“æŸå¤„ç†
                    if finish_called:
                        return

                    # å‡†å¤‡ä¸‹ä¸€è½®è¯·æ±‚
                    combined_tool_response = "\n".join(tool_responses)
                    tool_str = json.dumps(
                        [{"name": tool_call["name"], "arguments": tool_call["arguments"]} for tool_call in tool_calls],
                        ensure_ascii=False)

                    # æ·»åŠ å·¥å…·è°ƒç”¨å’Œå“åº”åˆ°æ¶ˆæ¯å†å²
                    self.chat_params["messages"].append(
                        {
                            "role": "assistant",
                            "content": f"ä½¿ç”¨å·¥å…·ï¼š \n {tool_str}\n"
                        }
                    )
                    self.chat_params["messages"].append(
                        {
                            "role": "user",
                            "content": combined_tool_response,
                        }
                    )

                    # åˆ›å»ºæ–°çš„å“åº”æµ
                    self.log("DEBUG", "stream next_request_params", {"params": self.chat_params})
                    response = self.client.chat.completions.create(**self.chat_params)
                    break

        # é‡è¯•æ¬¡æ•°ç”¨å°½
        self.log("ERROR", "max_retry_reached", {"message": "Failed to stream a valid response."})
        yield "Failed to stream a valid response."

    def _handle_task_transfer(
            self,
            query: str,
            light_swarm: 'LightSwarm',
            stream: bool = False,
    ) -> Union[Generator[str, None, None], str, None]:
        """
        å¤„ç†ä»»åŠ¡è½¬ç§»é€»è¾‘ã€‚

        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :param stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºã€‚
        :return: å¦‚æœä»»åŠ¡éœ€è¦è½¬ç§»ï¼Œè¿”å›ç”Ÿæˆå™¨æˆ–å­—ç¬¦ä¸²ï¼›å¦åˆ™è¿”å› Noneã€‚
        """
        intent = self._detect_intent(query, light_swarm)
        if intent and intent.get("transfer_to"):
            target_agent_name = intent["transfer_to"]
            self.log("INFO", "detect_intent", {"intent": intent})
            if target_agent_name == self.name:
                self.log("INFO", "self_transfer_detected", {"target_agent": target_agent_name})
                return None  # å¦‚æœæ˜¯è‡ªèº«ï¼Œç›´æ¥è¿”å› None
            if stream:
                return self._handle_task_transfer_stream(light_swarm.agents[target_agent_name], query, light_swarm)
            else:
                return self._handle_task_transfer_non_stream(light_swarm.agents[target_agent_name], query, light_swarm)
        return None

    def _handle_task_transfer_stream(
            self,
            target_agent: 'LightAgent',
            context: str,
            light_swarm: 'LightSwarm',
    ) -> Generator[str, None, None]:
        """
        å¤„ç†ä»»åŠ¡è½¬ç§»é€»è¾‘ï¼ˆæµå¼è¾“å‡ºï¼‰ã€‚

        :param target_agent: ç›®æ ‡ä»£ç†ã€‚
        :param context: å…±äº«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :return: ç”Ÿæˆå™¨ï¼Œç”¨äºæµå¼è¾“å‡ºã€‚
        """
        self.log("INFO", "transfer_to_agent", {"from": self.name, "to": target_agent.name, "context": context})

        # æ£€æŸ¥ç›®æ ‡ä»£ç†æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(target_agent, 'run'):
            self.log("ERROR", "invalid_target_agent", {"target_agent": target_agent})
            yield "Failed to transfer task: invalid target agent"
            return

        try:
            yield from target_agent.run(context, light_swarm=light_swarm, stream=True)
        except Exception as e:
            self.log("ERROR", "run_failed", {"error": str(e)})
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•

    def _handle_task_transfer_non_stream(
            self,
            target_agent: 'LightAgent',
            context: str,
            light_swarm: 'LightSwarm',
    ) -> str:
        """
        å¤„ç†ä»»åŠ¡è½¬ç§»é€»è¾‘ï¼ˆéæµå¼è¾“å‡ºï¼‰ã€‚

        :param target_agent: ç›®æ ‡ä»£ç†ã€‚
        :param context: å…±äº«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :return: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºéæµå¼è¾“å‡ºç»“æœã€‚
        """
        self.log("INFO", "transfer_to_agent", {"from": self.name, "to": target_agent.name, "context": context})

        # æ£€æŸ¥ç›®æ ‡ä»£ç†æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(target_agent, 'run'):
            self.log("ERROR", "invalid_target_agent", {"target_agent": target_agent})
            return "Failed to transfer task: invalid target agent"

        try:
            result = target_agent.run(context, light_swarm=light_swarm, stream=False)
            if isinstance(result, Generator):
                return "".join(result)  # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return result
        except Exception as e:
            self.log("ERROR", "run_failed", {"error": str(e)})
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•

    def _build_context(self, related_memories):
        """
        æ„å»ºä¸Šä¸‹æ–‡ï¼Œå°†ç”¨æˆ·è¾“å…¥å’Œè®°å¿†å†…å®¹ç»“åˆã€‚
        :param related_memories: ä»è®°å¿†ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ã€‚
        :return: ç»“åˆè®°å¿†åçš„ä¸Šä¸‹æ–‡ã€‚
        """
        if not related_memories or not related_memories["results"]:
            return ""

        memory_context = "\n".join([m["memory"] for m in related_memories["results"]])
        if not memory_context:
            return ""

        prompt = f"\n##ç”¨æˆ·åå¥½ \nç”¨æˆ·ä¹‹å‰æåˆ°äº†\n{memory_context}ã€‚"
        self.log("DEBUG", "related_memories", {"memory_context": memory_context})
        return prompt

    def _build_agent_memory(self, agent_memories):
        """
        æ„å»ºä¸Šä¸‹æ–‡ï¼Œå°†ç”¨æˆ·è¾“å…¥å’Œè®°å¿†å†…å®¹ç»“åˆã€‚

        :param agent_memories: ä»è®°å¿†ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ã€‚
        :return: ç»“åˆè®°å¿†åçš„ä¸Šä¸‹æ–‡ã€‚
        """
        if not agent_memories or not agent_memories["results"]:
            return ""

        memory_context = "\n".join([m["memory"] for m in agent_memories["results"]])
        if not memory_context:
            return ""

        prompt = f"\n##ä»¥ä¸‹æ˜¯è§£å†³è¯¥é—®é¢˜çš„ç›¸å…³è¡¥å……ä¿¡æ¯ï¼š\n{memory_context}ã€‚"
        self.log("DEBUG", "agent_memories", {"memory_context": memory_context})
        return prompt

    def run_thought(self, query: str, runtime_tools: List[Dict] | None = None) -> tuple:
        """ä½¿ç”¨æ€ç»´æ ‘çš„æ–¹å¼ è®©å¤§æ¨¡å‹å…ˆæ ¹æ®get_tools_strç”Ÿæˆä¸€ä¸ªè§£ç­”ç”¨æˆ·queryçš„å·¥å…·ä½¿ç”¨è®¡åˆ’"""
        tot_model = self.tot_model
        # ä¿®æ”¹ï¼šä¼˜å…ˆä½¿ç”¨è¿è¡Œæ—¶å·¥å…·ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åˆå§‹åŒ–æ—¶çš„å·¥å…·
        if runtime_tools:
            # å°†runtime_toolsè½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼
            tools_str = json.dumps(runtime_tools, indent=4, ensure_ascii=False)
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ToolRegistryæ¥è¿‡æ»¤å·¥å…·
            temp_registry = ToolRegistry()
            # å°†runtime_toolsæ³¨å†Œåˆ°ä¸´æ—¶æ³¨å†Œè¡¨ä¸­
            for tool_schema in runtime_tools:
                # è¿™é‡Œéœ€è¦å°†OpenAIæ ¼å¼çš„å·¥å…·schemaè½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
                # ç”±äºæ—¶é—´å…³ç³»ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è½¬æ¢
                pass
        else:
            tools = self.tool_registry.get_tools_str()

        if not isinstance(tools, str):
            tools = str(tools)  # ç¡®ä¿ tools æ˜¯å­—ç¬¦ä¸²
        now = datetime.now()
        current_date = now.strftime("%Y-%m-%d")
        current_time = now.strftime("%H:%M:%S")

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜ï¼Œç»“åˆå·¥å…·ä½¿ç”¨è®¡åˆ’ï¼Œç”Ÿæˆä¸€ä¸ªæ€ç»´æ ‘ï¼Œå¹¶æŒ‰ç…§æ€ç»´æ ‘ä¾æ¬¡è°ƒç”¨å·¥å…·æ­¥éª¤ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä¸ªæœ€ç»ˆå›ç­”ã€‚\n ä»Šæ—¥çš„æ—¥æœŸ: {current_date} å½“å‰æ—¶é—´: {current_time} \n å·¥å…·åˆ—è¡¨: {tools}"""
        self.log("DEBUG", "run_thought", {"system_prompt": system_prompt})

        try:
            # 1. ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œç”Ÿæˆåˆå§‹çš„å·¥å…·ä½¿ç”¨è®¡åˆ’
            params = dict(model=tot_model,
                          messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": query}],
                          stream=False)
            response = self.tot_client.chat.completions.create(**params)
            thought_response = response.choices[0].message.content
            self.log("DEBUG", "thought_response", {"response": thought_response})

            # 2. ç¬¬äºŒæ¬¡è¯·æ±‚ï¼Œè¯·æ±‚å¤§æ¨¡å‹åæ€å¹¶ç”Ÿæˆæ–°çš„å·¥å…·ä½¿ç”¨è§„åˆ’
            reflection_prompt = "è¯·åæ€ä½ çš„å›ç­”ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§<å·¥å…·åˆ—è¡¨>ä¸­çš„å·¥å…·æ¥è§„åˆ’ï¼Œä¸å¯ä»¥åˆ›é€ å…¶ä»–æ–°çš„å·¥å…·ã€‚è¯·è¾“å‡ºæ–°çš„ä»»åŠ¡è§„åˆ’ï¼Œä¸è¦è¾“å‡ºå…¶ä»–åˆ†æå’Œå›ç­”ã€‚"
            reflection_params = dict(model=tot_model, messages=[
                {"role": "user", "content": f"{system_prompt} /n å¼€å§‹æ€è€ƒé—®é¢˜: {query}"},
                {"role": "assistant", "content": thought_response},
                {"role": "user", "content": reflection_prompt}
            ], stream=False)
            self.log("DEBUG", "reflection_params", {"params": reflection_params})
            reflection_response = self.tot_client.chat.completions.create(**reflection_params)
            refined_content = reflection_response.choices[0].message.content
            self.log("DEBUG", "reflection_response", {"response": refined_content})

            # è·å–å·¥å…·çš„ä½¿ç”¨é›†åˆ
            tool_reflection_prompt = """è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è¦æ±‚æ‰§è¡Œï¼š
            1. åˆ†æé—®é¢˜éœ€æ±‚å¹¶è§„åˆ’éœ€è¦ä½¿ç”¨çš„å·¥å…·
            2. ä»…è¾“å‡ºåŒ…å«å·¥å…·åç§°çš„JSONæ ¼å¼ç»“æœ
            3. ä½¿ç”¨ä»¥ä¸‹ç»“æ„ï¼ˆç¤ºä¾‹ï¼‰ï¼š
            {"tools": [{"name": "å·¥å…·åç§°1"}, {"name": "å·¥å…·åç§°2"}]}
            4. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§å†…å®¹"""

            tool_reflection_params = dict(
                model=tot_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"é—®é¢˜åˆ†æè¯·æ±‚ï¼š{query}"},
                    {"role": "assistant", "content": refined_content},
                    {"role": "user", "content": tool_reflection_prompt}
                ],
                response_format={"type": "json_object"},  # å¼ºåˆ¶JSONè¾“å‡ºæ ¼å¼
                stream=False
            )

            self.log("DEBUG", "tool_reflection_params", {"params": tool_reflection_params})
            tool_reflection_response = self.tot_client.chat.completions.create(**tool_reflection_params)
            tool_reflection_result = tool_reflection_response.choices[0].message.content
            self.log("DEBUG", "tool_reflection_result", {"result": tool_reflection_result})

            # 3.æ‰§è¡Œè‡ªé€‚åº”å·¥å…·è¿‡æ»¤
            current_tools = []
            if self.filter_tools:
                # ä¿®æ”¹ï¼šä¼˜å…ˆä½¿ç”¨è¿è¡Œæ—¶å·¥å…·è¿›è¡Œè¿‡æ»¤
                if runtime_tools:
                    # ä½¿ç”¨ä¸´æ—¶æ³¨å†Œè¡¨è¿›è¡Œè¿‡æ»¤
                    temp_registry = ToolRegistry()
                    for tool_schema in runtime_tools:
                        # è¿™é‡Œéœ€è¦å°†OpenAIæ ¼å¼çš„schemaè½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
                        # ç®€åŒ–å¤„ç†ï¼šç›´æ¥æ·»åŠ åˆ°æ³¨å†Œè¡¨ä¸­
                        pass
                    current_tools = runtime_tools  # æš‚æ—¶ç›´æ¥ä½¿ç”¨è¿è¡Œæ—¶å·¥å…·
                else:
                    current_tools = self.tool_registry.filter_tools(tool_reflection_result)
                self.log("DEBUG", "current_tools", {"get_tools": current_tools})

            return refined_content, current_tools

        except Exception as e:
            self.log("ERROR", "run_thought_failure", {"error": str(e)})
            raise RuntimeError(f"æ€ç»´é“¾æ‰§è¡Œå¤±è´¥: {str(e)}") from e

    def _detect_intent(self, query: str, light_swarm=None) -> Optional[Dict]:
        """
        ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­ç”¨æˆ·æ„å›¾ã€‚

        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ï¼Œç”¨äºè·å–æ‰€æœ‰ä»£ç†ä¿¡æ¯ã€‚
        :return: æ„å›¾ä¿¡æ¯ï¼Œä¾‹å¦‚ {"transfer_to": "Agent B"}ã€‚
        """
        if not light_swarm:
            return None

        # è·å–æ‰€æœ‰ä»£ç†çš„ä¿¡æ¯
        agents_info = []
        for agent_name, agent in light_swarm.agents.items():
            agents_info.append(f"ä»£ç†åç§°: {agent_name}, ä»£ç†æŒ‡ä»¤: {agent.instructions}")

        # å°†ä»£ç†ä¿¡æ¯æ‹¼æ¥ä¸ºå­—ç¬¦ä¸²
        agents_info_str = "\n".join(agents_info)

        # æ„å»ºæç¤ºè¯
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„æ„å›¾ï¼Œå¦‚æœéœ€è¦è½¬ç§»ä»»åŠ¡ï¼Œè¯·è¿”å›ç›®æ ‡ä»£ç†çš„åç§°æ ¼å¼å¦‚ä¸‹ã€‚
        transfer to agent_name
        ä»¥ä¸‹æ˜¯æ‰€æœ‰å¯ç”¨ä»£ç†çš„ä¿¡æ¯ï¼š
    {agents_info_str}
    ç”¨æˆ·è¾“å…¥: {query}
è¯·è¿”å›ç›®æ ‡ä»£ç†çš„åç§°ï¼š
"""

        # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾åˆ¤æ–­
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": prompt}]
        )
        intent = response.choices[0].message.content
        self.log("DEBUG", "detect_intent", {"intent": intent})

        # # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£ææ„å›¾
        # match = re.search(r"transfer to (\w+)", intent, re.IGNORECASE)
        # if match:
        #     target_agent_name = match.group(1)
        #     if target_agent_name in light_swarm.agents:
        #         return {"transfer_to": target_agent_name}
        # return None

        # è§£ææ„å›¾
        for agent_name in light_swarm.agents.keys():
            if f"transfer to {agent_name}" in intent:
                return {"transfer_to": agent_name}
        return None

    def _transfer_to_agent(
            self,
            target_agent: 'LightAgent',
            context: str,
            light_swarm=None,
            stream: bool = False,
    ) -> Union[Generator[str, None, None], str]:
        """
        å°†ä»»åŠ¡è½¬ç§»ç»™å¦ä¸€ä¸ªä»£ç†ï¼Œæ”¯æŒæµå¼å’Œéæµå¼è¾“å‡ºã€‚

        :param target_agent: ç›®æ ‡ä»£ç†ã€‚
        :param context: å…±äº«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :param stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºã€‚
        :return: å¦‚æœ stream=Trueï¼Œè¿”å›ç”Ÿæˆå™¨ï¼›å¦åˆ™è¿”å›å®Œæ•´ç»“æœå­—ç¬¦ä¸²ã€‚
        """
        self.log("INFO", "transfer_to_agent", {"from": self.name, "to": target_agent.name, "context": context})

        # æ£€æŸ¥ç›®æ ‡ä»£ç†æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(target_agent, 'run'):
            self.log("ERROR", "invalid_target_agent", {"target_agent": target_agent})
            return "Failed to transfer task: invalid target agent"
        #
        # # è°ƒç”¨ç›®æ ‡ä»£ç†çš„ run æ–¹æ³•
        # if stream:
        #     yield from target_agent.run(context, light_swarm=light_swarm, stream=stream)
        # else:
        #     result = target_agent.run(context, light_swarm=light_swarm, stream=stream)
        #     if isinstance(result, Generator):
        #         return "".join(result)  # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        #     return result
        try:
            if stream:
                yield from target_agent.run(context, light_swarm=light_swarm, stream=stream)
            else:
                result = target_agent.run(context, light_swarm=light_swarm, stream=stream)
                if isinstance(result, Generator):
                    return "".join(result)  # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return result
        except Exception as e:
            self.log("ERROR", "run_failed", {"error": str(e)})
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•

    def create_tool(self, user_input: str, tools_directory: str = "tools"):
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ç”Ÿæˆ Python ä»£ç ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºå·¥å…·
        """
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ Python ä»£ç 
        system_prompt = """
        The user will provide some exam text. Please parse the "tool_name" and "code" and output them in JSON format. 

        EXAMPLE INPUT: 
        è¯·æ ¹æ®æ–‡æ¡£ç”Ÿæˆä¸€ä¸ªå¤©æ°”è°ƒç”¨çš„å·¥å…·ï¼ŒAPIä»‹ç»å¦‚ä¸‹

        EXAMPLE JSON OUTPUT:
        {'tools': [{
            "tool_name": "get_weather",
            "tool_code": "import requests
            def get_weather(
        city_name: str
) -> str:
    /"/"/"
    Get the current weather for `city_name`
    /"/"/"
    if not isinstance(city_name, str):
        raise TypeError("City name must be a string")

    key_selection = {
        "current_condition": ["temp_C", "FeelsLikeC", "humidity", "weatherDesc", "observation_time"],
    }
    try:
        resp = requests.get(f"https://wttr.in/{city_name}?format=j1")
        resp.raise_for_status()
        resp = resp.json()
        ret = {k: {_v: resp[k][0][_v] for _v in v} for k, v in key_selection.items()}
    except:
        import traceback
        ret = "Error encountered while fetching weather data!\n" + traceback.format_exc()

    return str(ret)

# åœ¨å‡½æ•°å†…éƒ¨å®šä¹‰å·¥å…·ä¿¡æ¯
get_weather.tool_info = {
    "tool_name": "get_weather",
    "tool_title": "å¤©æ°”æŸ¥è¯¢",
    "tool_description": "è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰å¤©æ°”ä¿¡æ¯",
    "tool_params": [
        {"name": "city_name", "description": "è¦æŸ¥è¯¢çš„åŸå¸‚åç§°", "type": "string", "required": True},
    ]
}"
        }]}
        """
        params = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": "You are a helpful assistant that generates Python code in JSON format."},
                {"role": "user", "content": f"Generate Python tools based on the following description. "
                                            f"Return a JSON array where each item contains 'tool_name' and 'tool_code'. "
                                            f"\n {system_prompt} "
                                            f"Description:\n{user_input}"},
            ],
            "response_format": {"type": "json_object"},
        }
        try:
            response = self.client.chat.completions.create(**params)
            response_data = json.loads(response.choices[0].message.content)

            # ç¡®ä¿è¿”å›çš„æ•°æ®æ˜¯ JSON å¯¹è±¡
            if not isinstance(response_data, dict):
                raise ValueError("Response is not a JSON object.")

            # éå†æ¯ä¸ªå·¥å…·
            for tool_data in response_data["tools"]:
                tool_name = tool_data.get("tool_name")
                tool_code = tool_data.get("tool_code")

                if not tool_name or not tool_code:
                    self.log("ERROR", "invalid_tool_data", {"tool_data": tool_data})
                    continue

                # ä¿å­˜ç”Ÿæˆçš„ä»£ç åˆ° tools ç›®å½•
                tool_path = os.path.join(tools_directory, f"{tool_name}.py")
                with open(tool_path, "w", encoding="utf-8") as f:
                    f.write(tool_code)
                self.log("INFO", "tool_created", {"tool_name": tool_name, "tool_path": tool_path})

                # è‡ªåŠ¨åŠ è½½æ–°åˆ›å»ºçš„å·¥å…·
                self.load_tools([tool_name], tools_directory)
        except Exception as e:
            self.log("ERROR", "tool_creation_failed", {"error": str(e)})


class LightSwarm:
    def __init__(self):
        self.agents: Dict[str, LightAgent] = {}

    def register_agent(self, *agents: LightAgent):
        """
        æ³¨å†Œä¸€ä¸ªæˆ–å¤šä¸ªä»£ç†ã€‚

        :param agents: è¦æ³¨å†Œçš„ä»£ç†å®ä¾‹ï¼Œæ”¯æŒå¤šä¸ªä»£ç†ã€‚
        """
        for agent in agents:
            if agent.name in self.agents:
                # print(f"Agent '{agent.name}' is already registered.")
                agent.log("INFO", "register_agent", {"agent_name": agent.name, "status": "already_registered"})
            else:
                self.agents[agent.name] = agent
                # print(f"Agent '{agent.name}' registered.")
                agent.log("INFO", "register_agent", {"agent_name": agent.name, "status": "registered"})

    def run(self, agent: LightAgent, query: str, stream=False):
        """
        è¿è¡ŒæŒ‡å®šä»£ç†ã€‚

        :param agent_name: ä»£ç†åç§°ã€‚
        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :return: ä»£ç†çš„å›å¤ã€‚
        """
        if agent.name not in self.agents:
            raise ValueError(f"Agent '{agent.name}' not found.")
        return agent.run(query, light_swarm=self, stream=stream)


if __name__ == "__main__":
    # Example of registering and using a tool
    print("This is LightAgent")
    # print(dispatch_tool("example_tool", {"param1": "test"}))
